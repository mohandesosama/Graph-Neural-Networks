{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7da158-442e-4aa6-a787-e57b59dce09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic node data...\n",
      "Node data generated with shape: (10000, 12)\n",
      "\n",
      "Generating synthetic edge data...\n",
      "Edge data generated with shape: (30000, 9)\n",
      "\n",
      "Saved node data to: enterprise_nodes.csv\n",
      "Saved edge data to: enterprise_edges.csv\n",
      "\n",
      "Data Statistics:\n",
      "- Sensitive nodes: 5763 (57.6%)\n",
      "- Average sprawl risk: 0.597\n",
      "- Node type distribution:\n",
      "type\n",
      "product_spec          1063\n",
      "contract              1040\n",
      "customer_data         1038\n",
      "database_backup       1015\n",
      "financial_report      1003\n",
      "meeting_minutes        994\n",
      "email                  985\n",
      "marketing_material     969\n",
      "source_code            969\n",
      "employee_record        924\n",
      "Name: count, dtype: int64\n",
      "\n",
      "- Edge relationship types:\n",
      "relationship_type\n",
      "email_attachment     5754\n",
      "backup_dependency    5226\n",
      "reference            3826\n",
      "access_grant         3815\n",
      "permission_share     3798\n",
      "version_history      3798\n",
      "data_flow            3783\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Initialize faker for realistic data generation\n",
    "fake = Faker()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# =============================================\n",
    "# Generate Node Data (Data Assets)\n",
    "# =============================================\n",
    "\n",
    "def generate_node_data(num_nodes=10000):\n",
    "    # Define data asset types with different sensitivity profiles\n",
    "    asset_types = [\n",
    "        'employee_record', 'financial_report', 'customer_data', \n",
    "        'source_code', 'marketing_material', 'meeting_minutes',\n",
    "        'product_spec', 'contract', 'email', 'database_backup'\n",
    "    ]\n",
    "    \n",
    "    # Generate nodes\n",
    "    nodes = []\n",
    "    for node_id in range(num_nodes):\n",
    "        # Randomly select asset type\n",
    "        asset_type = random.choice(asset_types)\n",
    "        \n",
    "        # Generate features based on type\n",
    "        size = int(np.random.lognormal(mean=8, sigma=2))  # File size in bytes\n",
    "        created_date = fake.date_time_between(start_date='-2y', end_date='now')\n",
    "        last_modified = fake.date_time_between(start_date=created_date, end_date='now')\n",
    "        last_accessed = fake.date_time_between(start_date=last_modified, end_date='now')\n",
    "        \n",
    "        # Generate sensitivity score (0-100) based on type and other factors\n",
    "        base_sensitivity = {\n",
    "            'employee_record': 80,\n",
    "            'financial_report': 90,\n",
    "            'customer_data': 85,\n",
    "            'source_code': 75,\n",
    "            'marketing_material': 30,\n",
    "            'meeting_minutes': 60,\n",
    "            'product_spec': 50,\n",
    "            'contract': 70,\n",
    "            'email': 40,\n",
    "            'database_backup': 95\n",
    "        }[asset_type]\n",
    "        \n",
    "        # Add variability to sensitivity\n",
    "        sensitivity_score = base_sensitivity + random.randint(-15, 15)\n",
    "        sensitivity_score = max(0, min(100, sensitivity_score))\n",
    "        \n",
    "        # Generate access frequency (higher for less sensitive data)\n",
    "        access_frequency = int(np.random.poisson(lam=100 - sensitivity_score * 0.7))\n",
    "        \n",
    "        # Determine if sensitive (label)\n",
    "        is_sensitive = 1 if sensitivity_score > 65 else 0\n",
    "        \n",
    "        nodes.append({\n",
    "            'node_id': node_id,\n",
    "            'type': asset_type,\n",
    "            'size': size,\n",
    "            'sensitivity_score': sensitivity_score,\n",
    "            'created_date': created_date.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'last_modified': last_modified.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'last_accessed': last_accessed.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'access_frequency': access_frequency,\n",
    "            'owner_department': fake.random_element(elements=(\n",
    "                'HR', 'Finance', 'Engineering', 'Marketing', 'Legal', 'Operations'\n",
    "            )),\n",
    "            'storage_location': fake.random_element(elements=(\n",
    "                'Cloud_Storage_A', 'Cloud_Storage_B', 'OnPrem_Server_1', \n",
    "                'OnPrem_Server_2', 'Endpoint_Device'\n",
    "            )),\n",
    "            'encryption_status': fake.random_element(elements=('encrypted', 'unencrypted')),\n",
    "            'sensitive_label': is_sensitive\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(nodes)\n",
    "\n",
    "# =============================================\n",
    "# Generate Edge Data (Relationships)\n",
    "# =============================================\n",
    "\n",
    "def generate_edge_data(node_df, num_edges=30000):\n",
    "    num_nodes = len(node_df)\n",
    "    edges = []\n",
    "    \n",
    "    # Create some clusters of highly connected nodes (simulating department structures)\n",
    "    department_groups = {}\n",
    "    for dept in node_df['owner_department'].unique():\n",
    "        dept_nodes = node_df[node_df['owner_department'] == dept]['node_id'].tolist()\n",
    "        department_groups[dept] = dept_nodes\n",
    "    \n",
    "    for edge_id in range(num_edges):\n",
    "        # 70% chance of intra-department edge, 30% inter-department\n",
    "        if random.random() < 0.7:\n",
    "            dept = random.choice(list(department_groups.keys()))\n",
    "            source = random.choice(department_groups[dept])\n",
    "            target = random.choice(department_groups[dept])\n",
    "        else:\n",
    "            source = random.randint(0, num_nodes-1)\n",
    "            target = random.randint(0, num_nodes-1)\n",
    "        \n",
    "        # Ensure no self-loops\n",
    "        while target == source:\n",
    "            target = random.randint(0, num_nodes-1)\n",
    "        \n",
    "        # Get node features to influence edge properties\n",
    "        src_node = node_df[node_df['node_id'] == source].iloc[0]\n",
    "        tgt_node = node_df[node_df['node_id'] == target].iloc[0]\n",
    "        \n",
    "        # Edge features\n",
    "        access_frequency = int(np.random.poisson(lam=((src_node['access_frequency'] + tgt_node['access_frequency']) / 4)))\n",
    "        \n",
    "        sharing_level = random.choice(['internal', 'restricted', 'confidential'])\n",
    "        \n",
    "        # Relationship type based on node types\n",
    "        if src_node['type'] == 'email' or tgt_node['type'] == 'email':\n",
    "            relationship_type = 'email_attachment'\n",
    "        elif src_node['type'] == 'database_backup' or tgt_node['type'] == 'database_backup':\n",
    "            relationship_type = 'backup_dependency'\n",
    "        else:\n",
    "            relationship_type = random.choice([\n",
    "                'access_grant', 'data_flow', 'version_history', \n",
    "                'reference', 'permission_share'\n",
    "            ])\n",
    "        \n",
    "        # Calculate sprawl risk score (0-1)\n",
    "        risk_score = (\n",
    "            0.4 * (src_node['sensitivity_score'] / 100) +\n",
    "            0.4 * (tgt_node['sensitivity_score'] / 100) +\n",
    "            0.1 * (1 if sharing_level == 'confidential' else 0) +\n",
    "            0.1 * (access_frequency / 100)\n",
    "        )\n",
    "        \n",
    "        # Add some noise\n",
    "        risk_score = min(1, max(0, risk_score + random.uniform(-0.1, 0.1)))\n",
    "        \n",
    "        edges.append({\n",
    "            'source': source,\n",
    "            'target': target,\n",
    "            'relationship_type': relationship_type,\n",
    "            'access_frequency': access_frequency,\n",
    "            'sharing_level': sharing_level,\n",
    "            'last_accessed': fake.date_time_between(\n",
    "                start_date=max(\n",
    "                    datetime.strptime(src_node['last_accessed'], '%Y-%m-%d %H:%M:%S'),\n",
    "                    datetime.strptime(tgt_node['last_accessed'], '%Y-%m-%d %H:%M:%S')\n",
    "                ),\n",
    "                end_date='now'\n",
    "            ).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'permission_type': fake.random_element(elements=(\n",
    "                'read', 'write', 'admin', 'share'\n",
    "            )),\n",
    "            'data_flow_direction': random.choice(['unidirectional', 'bidirectional']),\n",
    "            'sprawl_risk': risk_score\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(edges)\n",
    "\n",
    "# =============================================\n",
    "# Main Execution\n",
    "# =============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Generating synthetic node data...\")\n",
    "    node_df = generate_node_data(10000)\n",
    "    print(\"Node data generated with shape:\", node_df.shape)\n",
    "    \n",
    "    print(\"\\nGenerating synthetic edge data...\")\n",
    "    edge_df = generate_edge_data(node_df, 30000)\n",
    "    print(\"Edge data generated with shape:\", edge_df.shape)\n",
    "    \n",
    "    # Save to CSV files\n",
    "    node_file = \"enterprise_nodes.csv\"\n",
    "    edge_file = \"enterprise_edges.csv\"\n",
    "    \n",
    "    node_df.to_csv(node_file, index=False)\n",
    "    edge_df.to_csv(edge_file, index=False)\n",
    "    \n",
    "    print(f\"\\nSaved node data to: {node_file}\")\n",
    "    print(f\"Saved edge data to: {edge_file}\")\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(\"\\nData Statistics:\")\n",
    "    print(f\"- Sensitive nodes: {node_df['sensitive_label'].sum()} ({node_df['sensitive_label'].mean()*100:.1f}%)\")\n",
    "    print(f\"- Average sprawl risk: {edge_df['sprawl_risk'].mean():.3f}\")\n",
    "    print(\"- Node type distribution:\")\n",
    "    print(node_df['type'].value_counts())\n",
    "    print(\"\\n- Edge relationship types:\")\n",
    "    print(edge_df['relationship_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bbf44-0732-486f-99b6-28f13476819d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
